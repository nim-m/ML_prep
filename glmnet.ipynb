{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e609d72-a02b-4755-b5e1-12c56d30a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "library(glmnet)\n",
    "library(caret)\n",
    "\n",
    "# Function to load data\n",
    "load_data <- function(data_path) {\n",
    "  data <- read.csv(data_path)\n",
    "  return(data)\n",
    "}\n",
    "\n",
    "# Function for data standardization\n",
    "standardize_data <- function(data) {\n",
    "  data_scaled <- scale(data)\n",
    "  return(data_scaled)\n",
    "}\n",
    "\n",
    "# Function to calculate metrics\n",
    "calculate_metrics <- function(true_values, predicted_values) {\n",
    "  # Calculate metrics (e.g., accuracy, precision, recall, etc.)\n",
    "  # Example: accuracy <- mean(true_values == predicted_values)\n",
    "  # Return metrics\n",
    "}\n",
    "\n",
    "# Function for k-fold cross-validation\n",
    "perform_k_fold_cv <- function(data, k) {\n",
    "  # Define k-fold indices\n",
    "  folds <- createFolds(data$target_variable, k = k, list = TRUE)\n",
    "  \n",
    "  # Initialize vectors to store performance metrics\n",
    "  # metrics_list <- list()\n",
    "  \n",
    "  # Perform k-fold cross-validation\n",
    "  for (i in 1:k) {\n",
    "    # Split data into training and testing sets based on fold indices\n",
    "    train_indices <- unlist(folds[-i])\n",
    "    test_indices <- unlist(folds[i])\n",
    "    train_data <- data[train_indices, ]\n",
    "    test_data <- data[test_indices, ]\n",
    "    \n",
    "    # Train elastic net model using glmnet\n",
    "    # Example:\n",
    "    # model <- glmnet(x = as.matrix(train_data[, -c(\"target_variable\")]), \n",
    "    #                 y = train_data$target_variable, \n",
    "    #                 alpha = 0.5, lambda = 0.1)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    # predicted_values <- predict(model, newx = as.matrix(test_data[, -c(\"target_variable\")]))\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    # metrics <- calculate_metrics(test_data$target_variable, predicted_values)\n",
    "    \n",
    "    # Store metrics for each fold\n",
    "    # metrics_list[[i]] <- metrics\n",
    "  }\n",
    "  \n",
    "  # Return performance metrics for all folds\n",
    "  # return(metrics_list)\n",
    "}\n",
    "\n",
    "# Example usage:\n",
    "# Load data\n",
    "# data <- load_data(\"your_data.csv\")\n",
    "\n",
    "# Standardize data\n",
    "# standardized_data <- standardize_data(data)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "# k_fold_metrics <- perform_k_fold_cv(standardized_data, k = 5)\n",
    "\n",
    "# Average and report performance metrics\n",
    "# mean_metrics <- lapply(k_fold_metrics, function(x) sapply(x, mean))\n",
    "# print(mean_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc38aff3-ab02-409d-86da-901d9dbe616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(glmnet)\n",
    "\n",
    "# Define your training control with stratified cross-validation\n",
    "ctrl <- trainControl(method = \"cv\",   # Cross-validation method\n",
    "                     number = k,      # Number of folds (k)\n",
    "                     classProbs = TRUE,  # Required for stratification\n",
    "                     summaryFunction = twoClassSummary,  # For binary classification\n",
    "                     stratify = TRUE)  # Enable stratified sampling\n",
    "\n",
    "# Train your model using train function with glmnet\n",
    "model <- train(y ~ .,                  # Formula defining your response variable and predictors\n",
    "               data = your_data,      # Your dataset\n",
    "               method = \"glmnet\",    # Specify \"glmnet\" for logistic regression with regularization\n",
    "               trControl = ctrl,     # Use the defined control\n",
    "               tuneGrid = expand.grid(alpha = 0:1,  # 0 for ridge, 1 for lasso\n",
    "                                        lambda = seq(0.001, 1, length = 100)))  # Regularization parameter grid\n",
    "\n",
    "# Access the model performance metrics\n",
    "summary(model)\n",
    "\n",
    "# Plot the cross-validation results\n",
    "plot(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b37842-190c-4f66-8484-93c717565b52",
   "metadata": {},
   "source": [
    "# Mimicking paper model (w/o stratified cross validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7a615c-b6b5-4f08-93e3-3cb8c5e56e2d",
   "metadata": {},
   "source": [
    "The data in the initial sample (n = 521) were randomly split into 60% training (n = 313), 20% validation (n = 104), and 20% testing data (n = 104) while keeping the proportion of lower IQ consistent across training, validation and testing sets (Table 1). The model training was conducted in the training set, the validation set was used to select the best performing model, and the testing set was used to decide the predictive probability cutoff and model evaluation. An evaluation was also conducted to assess the model performance in the presence of missing values (up to 70%) in an additional independent set (n = 1346; Figure 1, Table 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6568cbd-a0a3-4bae-80f0-707c683a1361",
   "metadata": {},
   "source": [
    "Five models to be tested:\n",
    "1. elastic-net regularized generalized linear models with no interaction terms (glmnet),\n",
    "2. support vector machines (svmRadial),\n",
    "3. random forest (rf),\n",
    "4. k-Nearest Neighbors (kNN), and\n",
    "5. gradient boosting (xgbTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f65d0-8786-4fe5-8aae-ccad15e2f2d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### data loading and factorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f9248149-5acb-4c7a-869a-42acabf468b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Done.\"\n"
     ]
    }
   ],
   "source": [
    "library(caret)\n",
    "library(glmnet)\n",
    "\n",
    "### DATA LOADING AND SPLITTING\n",
    "### ------------------------------------------------------\n",
    "\n",
    "df <- read.csv(\"ref129_less18_fsiq_1554.csv\")\n",
    "\n",
    "dropped_paras = c('subject_sp_id','derived_cog_impair','asd', 'fsiq', 'fsiq_score', 'fsiq_80')\n",
    "df <- df[, !(names(df) %in% dropped_paras)]\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6bd8ae8-f6d4-4b81-be33-1bc3abb957fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Done.\"\n"
     ]
    }
   ],
   "source": [
    "parameters <- c(\n",
    "  \"q02_catch_ball_2.0\", \"q02_catch_ball_3.0\", \"q02_catch_ball_4.0\", \"q02_catch_ball_5.0\",\n",
    "  \"q05_run_fast_similar_1.0\", \"q05_run_fast_similar_2.0\", \"q05_run_fast_similar_3.0\", \"q05_run_fast_similar_4.0\", \"q05_run_fast_similar_5.0\",\n",
    "  \"q06_plan_motor_activity_1.0\", \"q06_plan_motor_activity_2.0\", \"q06_plan_motor_activity_3.0\", \"q06_plan_motor_activity_4.0\", \"q06_plan_motor_activity_5.0\",\n",
    "  \"q09_appropriate_tension_printing_writing_1.0\", \"q09_appropriate_tension_printing_writing_2.0\", \"q09_appropriate_tension_printing_writing_3.0\", \"q09_appropriate_tension_printing_writing_4.0\", \"q09_appropriate_tension_printing_writing_5.0\",\n",
    "  \"q10_cuts_pictures_shapes_1.0\", \"q10_cuts_pictures_shapes_2.0\", \"q10_cuts_pictures_shapes_3.0\", \"q10_cuts_pictures_shapes_4.0\", \"q10_cuts_pictures_shapes_5.0\",\n",
    "  \"q11_likes_sports_motors_skills_1.0\", \"q11_likes_sports_motors_skills_2.0\", \"q11_likes_sports_motors_skills_3.0\", \"q11_likes_sports_motors_skills_4.0\", \"q11_likes_sports_motors_skills_5.0\",\n",
    "  \"q13_quick_competent_tidying_up_1.0\", \"q13_quick_competent_tidying_up_2.0\", \"q13_quick_competent_tidying_up_3.0\", \"q13_quick_competent_tidying_up_4.0\", \"q13_quick_competent_tidying_up_5.0\",\n",
    "  \"q01_whole_body_0.0\", \"q01_whole_body_1.0\", \"q01_whole_body_2.0\", \"q01_whole_body_3.0\",\n",
    "  \"q03_hand_finger_0.0\", \"q03_hand_finger_1.0\", \"q03_hand_finger_2.0\", \"q03_hand_finger_3.0\",\n",
    "  \"q07_hits_self_body_0.0\", \"q07_hits_self_body_1.0\", \"q07_hits_self_body_2.0\", \"q07_hits_self_body_3.0\",\n",
    "  \"q08_hits_self_against_object_0.0\", \"q08_hits_self_against_object_1.0\", \"q08_hits_self_against_object_2.0\", \"q08_hits_self_against_object_3.0\",\n",
    "  \"q09_hits_self_with_object_0.0\", \"q09_hits_self_with_object_1.0\", \"q09_hits_self_with_object_2.0\", \"q09_hits_self_with_object_3.0\",\n",
    "  \"q12_rubs_0.0\", \"q12_rubs_1.0\", \"q12_rubs_2.0\", \"q12_rubs_3.0\",\n",
    "  \"q16_complete_0.0\", \"q16_complete_1.0\", \"q16_complete_2.0\", \"q16_complete_3.0\",\n",
    "  \"q18_checking_0.0\", \"q18_checking_1.0\", \"q18_checking_2.0\", \"q18_checking_3.0\",\n",
    "  \"q19_counting_0.0\", \"q19_counting_1.0\", \"q19_counting_2.0\", \"q19_counting_3.0\",\n",
    "  \"q22_touch_tap_0.0\", \"q22_touch_tap_1.0\", \"q22_touch_tap_2.0\", \"q22_touch_tap_3.0\",\n",
    "  \"q32_insists_walking_0.0\", \"q32_insists_walking_1.0\", \"q32_insists_walking_2.0\", \"q32_insists_walking_3.0\",\n",
    "  \"q27_play_0.0\", \"q27_play_1.0\", \"q27_play_2.0\", \"q27_play_3.0\",\n",
    "  \"q28_communication_0.0\", \"q28_communication_1.0\", \"q28_communication_2.0\", \"q28_communication_3.0\",\n",
    "  \"q29_things_same_place_0.0\", \"q29_things_same_place_1.0\", \"q29_things_same_place_2.0\", \"q29_things_same_place_3.0\",\n",
    "  \"q31_becomes_upset_0.0\", \"q31_becomes_upset_1.0\", \"q31_becomes_upset_2.0\", \"q31_becomes_upset_3.0\",\n",
    "  \"q34_dislikes_changes_0.0\", \"q34_dislikes_changes_1.0\", \"q34_dislikes_changes_2.0\", \"q34_dislikes_changes_3.0\",\n",
    "  \"q35_insists_door_0.0\", \"q35_insists_door_1.0\", \"q35_insists_door_2.0\", \"q35_insists_door_3.0\",\n",
    "  \"q36_likes_piece_music_0.0\", \"q36_likes_piece_music_1.0\", \"q36_likes_piece_music_2.0\", \"q36_likes_piece_music_3.0\",\n",
    "  \"q39_insists_time_0.0\", \"q39_insists_time_1.0\", \"q39_insists_time_2.0\", \"q39_insists_time_3.0\",\n",
    "  \"q41_strongly_attached_0.0\", \"q41_strongly_attached_1.0\", \"q41_strongly_attached_2.0\", \"q41_strongly_attached_3.0\",\n",
    "  \"q43_fascination_movement_0.0\", \"q43_fascination_movement_1.0\", \"q43_fascination_movement_2.0\"\n",
    ")\n",
    "\n",
    "\n",
    "df[parameters] <- lapply(df[parameters], function(x) as.numeric(as.logical(x)))\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ea0656-616b-4770-8e2e-91d4c374d8ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "77b114f5-a1bd-4d27-a459-4f430f0d94d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Done.\"\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "set.seed(123)\n",
    "\n",
    "# Create a vector of indices for stratified sampling\n",
    "train_index <- createDataPartition(df$fsiq_70, p = 0.6, list = FALSE, times = 1)\n",
    "remaining_data <- df[-train_index, ]\n",
    "\n",
    "# Now create test and validation sets from the remaining data\n",
    "test_index <- createDataPartition(remaining_data$fsiq_70, p = 0.5, list = FALSE, times = 1)\n",
    "valid_index <- setdiff(seq(nrow(remaining_data)), test_index)\n",
    "\n",
    "# Split the dataset\n",
    "train_data <- df[train_index, ]\n",
    "valid_data <- df[valid_index, ]\n",
    "test_data <- df[test_index, ]\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c14a8561-d98f-416a-aa81-c184ab282385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>933</li><li>224</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 933\n",
       "\\item 224\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 933\n",
       "2. 224\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 933 224"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>310</li><li>224</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 310\n",
       "\\item 224\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 310\n",
       "2. 224\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 310 224"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>311</li><li>224</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 311\n",
       "\\item 224\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 311\n",
       "2. 224\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 311 224"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(train_data)\n",
    "dim(valid_data)\n",
    "dim(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db19f90b-ff08-447e-989d-44157e8b404a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### minmax scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ecd12bd-ca65-4b5a-91ff-1034140b9f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Done.\"\n"
     ]
    }
   ],
   "source": [
    "### MINMAX SCALING\n",
    "### ------------------------------------------------------\n",
    "\n",
    "# Define the parameters for Min-Max scaling\n",
    "parameters_to_scale <- c(\"age_onset_mos\", \"fed_self_spoon_age_mos\", \"smiled_age_mos\", \"fine_motor_handwriting\")  \n",
    "\n",
    "# Perform Min-Max scaling on the training set\n",
    "train_data_orig <- train_data  # Make a copy of the training data\n",
    "train_data[, parameters_to_scale] <- apply(train_data[, parameters_to_scale], 2, function(x) (x - min(x)) / (max(x) - min(x)))\n",
    "\n",
    "# Perform Min-Max scaling on the validation set\n",
    "valid_data_orig <- valid_data  # Make a copy of the validation data\n",
    "valid_data[, parameters_to_scale] <- apply(valid_data[, parameters_to_scale], 2, function(x) (x - min(x)) / (max(x) - min(x)))\n",
    "\n",
    "# Perform Min-Max scaling on the testing set\n",
    "test_data_orig <- test_data  # Make a copy of the testing data\n",
    "test_data[, parameters_to_scale] <- apply(test_data[, parameters_to_scale], 2, function(x) (x - min(x)) / (max(x) - min(x)))\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515b5aae-235f-4929-a7b4-0c68fbdf8a49",
   "metadata": {},
   "source": [
    "### drop parameters + extract X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0b6f62f7-604e-4381-90db-7f74f68e0ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Done.\"\n"
     ]
    }
   ],
   "source": [
    "# For train set\n",
    "X_train <- train_data[, !(names(train_data) %in% \"fsiq_70\")]\n",
    "y_train <- train_data$fsiq_70\n",
    "y_train <- factor(y_train, levels = c(\"0\", \"1\"))  # factorise\n",
    "\n",
    "# For validation set\n",
    "X_valid <- valid_data[, !(names(valid_data) %in% \"fsiq_70\")]\n",
    "y_valid <- valid_data$fsiq_70\n",
    "y_train <- factor(y_train, levels = c(\"0\", \"1\"))  # factorise\n",
    "\n",
    "\n",
    "# For test set\n",
    "X_test <- test_data[, !(names(test_data) %in% \"fsiq_70\")]\n",
    "y_test <- test_data$fsiq_70\n",
    "y_train <- factor(y_train, levels = c(\"0\", \"1\"))  # factorise\n",
    "\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1deffa5-1428-4a6f-829b-8ee0cab92acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in read.dcf(file.path(p, \"DESCRIPTION\"), c(\"Package\", \"Version\")):\n",
      "\"cannot open compressed file 'D:/SOFTWARE/R-4.3.1/library/Matrix/DESCRIPTION', probable reason 'No such file or directory'\"\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error: Required packages are missing: Matrix\n",
     "output_type": "error",
     "traceback": [
      "Error: Required packages are missing: Matrix\nTraceback:\n",
      "1. train(y_train ~ ., data = X_train, method = \"glmnet\")",
      "2. train.formula(y_train ~ ., data = X_train, method = \"glmnet\")",
      "3. train(x, y, weights = w, ...)",
      "4. train.default(x, y, weights = w, ...)",
      "5. checkInstall(models$library)",
      "6. stop(\"Required packages are missing: \", pkList, call. = FALSE)"
     ]
    }
   ],
   "source": [
    "library(Matrix) \n",
    "\n",
    "# Model Training\n",
    "model_glmnet <- train(y_train ~ ., data = X_train, method = \"glmnet\")\n",
    "model_svmRadial <- train(y_train ~ ., data = X_train, method = \"svmRadial\")\n",
    "model_rf <- train(y_train ~ ., data = X_train, method = \"rf\")\n",
    "model_kNN <- train(y_train ~ ., data = X_train, method = \"knn\")\n",
    "model_xgbTree <- train(y_train ~ ., data = X_train, method = \"xgbTree\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b523453-ebd9-4e95-ae89-5ce48664f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set -> to select the best performing model\n",
    "valid_perf_glmnet <- predict(model_glmnet, newx = as.matrix(X_valid), type = \"response\")\n",
    "valid_perf_svmRadial <- predict(model_svmRadial, newdata = X_valid)\n",
    "valid_perf_rf <- predict(model_rf, newdata = X_valid)\n",
    "#valid_perf_kNN <- predict(model_kNN, newdata = X_test, type = \"prob\")\n",
    "valid_perf_kNN <- predict(model_kNN, newdata = as.matrix(X_valid), type = \"prob\")\n",
    "valid_perf_xgbTree <- predict(model_xgbTree, newdata = as.matrix(X_valid))\n",
    "\n",
    "print(\"Validation done.\")\n",
    "\n",
    "# Testing set -> to decide the predictive probability cutoff and model evaluation\n",
    "test_perf_glmnet <- predict(model_glmnet, newx = as.matrix(X_test), type = \"response\")\n",
    "test_perf_svmRadial <- predict(model_svmRadial, newdata = X_test)\n",
    "test_perf_rf <- predict(model_rf, newdata = X_test)\n",
    "# test_perf_kNN <- knn(train = as.matrix(X_train), test = as.matrix(X_test), cl = y_test)\n",
    "test_perf_xgbTree <- predict(model_xgbTree, newdata = as.matrix(X_test))\n",
    "\n",
    "print(\"Testing done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaae32c-e45c-4f7a-b69e-22cde4b21305",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Independent set\n",
    "\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ae175-78a6-424c-9ef7-f2764f391120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate F1-score\n",
    "calculate_f1_score <- function(true_labels, predicted_labels) {\n",
    "  confusion_matrix <- table(true_labels, predicted_labels)\n",
    "  precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])\n",
    "  recall <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])\n",
    "  f1_score <- 2 * precision * recall / (precision + recall)\n",
    "  return(f1_score)\n",
    "}\n",
    "\n",
    "# Function to calculate accuracy, AUC, and F1-score\n",
    "calculate_metrics <- function(true_labels, predicted_probs, cutoff) {\n",
    "  predicted_labels <- ifelse(predicted_probs > cutoff, 1, 0)\n",
    "  accuracy <- mean(predicted_labels == true_labels)\n",
    "  auc <- AUC(prediction(predicted_probs, true_labels))\n",
    "  f1_score <- calculate_f1_score(true_labels, predicted_labels)\n",
    "  return(list(accuracy = accuracy, auc = auc, f1_score = f1_score))\n",
    "}\n",
    "\n",
    "\n",
    "# Determine the predictive probability cutoff for each model\n",
    "cutoff_glmnet <- optimalCutoff(test_perf_glmnet$obs, test_perf_glmnet$glmnet, opt.methods = \"youden\")\n",
    "cutoff_svmRadial <- optimalCutoff(test_perf_svmRadial$obs, test_perf_svmRadial$svmRadial, opt.methods = \"youden\")\n",
    "cutoff_rf <- optimalCutoff(test_perf_rf$obs, test_perf_rf$rf, opt.methods = \"youden\")\n",
    "#cutoff_kNN <- optimalCutoff(test_perf_kNN$obs, test_perf_kNN$kNN, opt.methods = \"youden\")\n",
    "cutoff_xgbTree <- optimalCutoff(test_perf_xgbTree$obs, test_perf_xgbTree$xgbTree, opt.methods = \"youden\")\n",
    "\n",
    "\n",
    "\n",
    "# Assess model performance on the testing set\n",
    "metrics_glmnet <- calculate_metrics(test_perf_glmnet$obs, test_perf_glmnet$glmnet, cutoff_glmnet)\n",
    "metrics_svmRadial <- calculate_metrics(test_perf_svmRadial$obs, test_perf_svmRadial$svmRadial, cutoff_svmRadial)\n",
    "metrics_rf <- calculate_metrics(test_perf_rf$obs, test_perf_rf$rf, cutoff_rf)\n",
    "# metrics_kNN <- calculate_metrics(test_perf_kNN$obs, test_perf_kNN$kNN, cutoff_kNN)\n",
    "metrics_xgbTree <- calculate_metrics(test_perf_xgbTree$obs, test_perf_xgbTree$xgbTree, cutoff_xgbTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011b8415-e095-4e0c-997f-d98eb0fb3a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895db77f-83ab-4467-a8eb-1ff7ea04c6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff9174-476c-4a7f-b326-9e2c115a0e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the glmnet model using a range of lambda values\n",
    "lambda_values <- seq(0.001, 1, by = 0.01)  # Define lambda values\n",
    "auc_scores <- numeric(length(lambda_values))  # Store AUC scores for each lambda\n",
    "\n",
    "for (i in 1:length(lambda_values)) {\n",
    "  # Train glmnet model with current lambda value\n",
    "  model <- glmnet(x = as.matrix(X_train), y = y_train_num, alpha = 0.1, lambda = lambda_values[i])\n",
    "  \n",
    "  # Make predictions on validation set\n",
    "  predictions <- predict(model, newx = as.matrix(X_val), s = lambda_values[i])\n",
    "\n",
    "  # Extract predicted probabilities for the positive class\n",
    "  # predictions_vector <- as.vector(final_predictions)\n",
    "  \n",
    "  # Calculate AUC\n",
    "  auc_scores[i] <- roc(y_val_num, predictions)$auc\n",
    "}\n",
    "\n",
    "avg_auc <- mean(auc_scores)\n",
    "print(avg_auc)\n",
    "\n",
    "# Find the index of the lambda value with the highest AUC\n",
    "best_lambda_index <- which.max(auc_scores)\n",
    "best_lambda <- lambda_values[best_lambda_index]\n",
    "\n",
    "# Train the final model using the best lambda value\n",
    "final_model <- glmnet(x = as.matrix(X_train), y = y_train_num, alpha = 0.1, lambda = best_lambda)\n",
    "\n",
    "# Make predictions on test set using the final model\n",
    "final_predictions <- predict(final_model, newx = as.matrix(X_test), s = best_lambda)\n",
    "\n",
    "# Extract predicted probabilities for the positive class\n",
    "final_predictions_vector <- as.vector(final_predictions)\n",
    "\n",
    "# Calculate AUC on the validation set\n",
    "final_auc <- roc(y_test_num, final_predictions_vector)$auc\n",
    "\n",
    "# Report the AUC score\n",
    "print(final_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dafab28-512a-4594-9817-d6d1af4e7265",
   "metadata": {},
   "source": [
    "alpha 0.1 \n",
    "    AUC test = 0.9 \n",
    "    AUC val = 0.8535\n",
    "\n",
    "alpha 0.5 AUC = 0.8972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c898ab7-665d-4a33-89ca-ca65a4be15d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_values <- seq(0.001, 1, by = 0.01)  # Define lambda values\n",
    "test_auc_scores <- numeric(length(lambda_values))\n",
    "\n",
    "for (i in 1:length(lambda_values)) {\n",
    "  # Make predictions on test set\n",
    "  predictions <- predict(model, newx = as.matrix(X_test), s = lambda_values[i])\n",
    "  \n",
    "  # Calculate AUC\n",
    "  test_auc_scores[i] <- roc(y_test_num, predictions)$auc\n",
    "}\n",
    "\n",
    "mean(test_auc_scores)\n",
    "sd(test_auc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21df082-3870-49cc-9cff-b25334d69a89",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a1db4-f5fb-4692-93e5-9dcb1a43355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the glmnet model using a range of lambda values\n",
    "lambda_values <- seq(0.001, 1, by = 0.01)  # Define lambda values\n",
    "auc_scores <- numeric(length(lambda_values))  # Store AUC scores for each lambda\n",
    "\n",
    "for (i in 1:length(lambda_values)) {\n",
    "  # Train glmnet model with current lambda value\n",
    "  model <- glmnet(x = as.matrix(X_train), y = y_train_num, alpha = 0.1, lambda = lambda_values[i])\n",
    "  \n",
    "  # Make predictions on validation set\n",
    "  predictions <- predict(model, newx = as.matrix(X_val), s = lambda_values[i])\n",
    "\n",
    "  # Extract predicted probabilities for the positive class\n",
    "  # predictions_vector <- as.vector(final_predictions)\n",
    "  \n",
    "  # Calculate AUC\n",
    "  auc_scores[i] <- roc(y_val_num, predictions)$auc\n",
    "}\n",
    "\n",
    "avg_auc <- mean(auc_scores)\n",
    "print(avg_auc)\n",
    "\n",
    "# Find the index of the lambda value with the highest AUC\n",
    "best_lambda_index <- which.max(auc_scores)\n",
    "best_lambda <- lambda_values[best_lambda_index]\n",
    "\n",
    "# Train the final model using the best lambda value\n",
    "final_model <- glmnet(x = as.matrix(X_train), y = y_train_num, alpha = 0.1, lambda = best_lambda)\n",
    "\n",
    "# Make predictions on test set using the final model\n",
    "final_predictions <- predict(final_model, newx = as.matrix(X_test), s = best_lambda)\n",
    "\n",
    "# Extract predicted probabilities for the positive class\n",
    "final_predictions_vector <- as.vector(final_predictions)\n",
    "\n",
    "# Calculate AUC on the validation set\n",
    "final_auc <- roc(y_test_num, final_predictions_vector)$auc\n",
    "\n",
    "# Report the AUC score\n",
    "print(final_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa5dac7-0403-4e7b-94eb-fb41417f98e4",
   "metadata": {},
   "source": [
    "### sensitivity, specificity, confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b1b93-e8e7-4bf0-b18d-50a50cf48529",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "\n",
    "cutoff = 0.5\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix <- confusionMatrix(data = as.factor(ifelse(final_predictions_vector > cutoff, 1, 0)),\n",
    "                               reference = as.factor(ifelse(y_test_num == 1, 1, 0)))\n",
    "\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa08bb87-0391-48b8-a69e-c50d00e11290",
   "metadata": {},
   "source": [
    "Confusion Matrix and Statistics\n",
    "\n",
    "          Reference\n",
    "Prediction   0   1\n",
    "         0 221  27\n",
    "         1  15  48\n",
    "                                          \n",
    "               Accuracy : 0.865           \n",
    "                 95% CI : (0.8219, 0.9009)\n",
    "    No Information Rate : 0.7588          \n",
    "    P-Value [Acc > NIR] : 2.444e-06       \n",
    "                                          \n",
    "                  Kappa : 0.6097          \n",
    "                                          \n",
    " Mcnemar's Test P-Value : 0.08963         \n",
    "                                          \n",
    "            Sensitivity : 0.9364          \n",
    "            Specificity : 0.6400          \n",
    "         Pos Pred Value : 0.8911          \n",
    "         Neg Pred Value : 0.7619          \n",
    "             Prevalence : 0.7588          \n",
    "         Detection Rate : 0.7106          \n",
    "   Detection Prevalence : 0.7974          \n",
    "      Balanced Accuracy : 0.7882          \n",
    "                                          \n",
    "       'Positive' Class : 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0904d51a-6d12-4ffb-b0b1-a0fd3e9d8699",
   "metadata": {},
   "source": [
    "## predictive probability determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f567f957-8eed-4c63-8378-e87c0de2a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set using the final model\n",
    "final_predictions <- predict(final_model, newx = as.matrix(X_test), s = best_lambda)\n",
    "final_predictions_vector <- as.vector(final_predictions)\n",
    "\n",
    "cutoff_values <- seq(0.1, 0.9, by = 0.01)\n",
    "\n",
    "# Initialize vectors \n",
    "sensitivity <- numeric(length(cutoff_values))\n",
    "specificity <- numeric(length(cutoff_values))\n",
    "accuracy <- numeric(length(cutoff_values))\n",
    "\n",
    "# Iterate over the range of cutoff values\n",
    "for (i in seq_along(cutoff_values)) {\n",
    "  # Convert predicted probabilities to binary predictions using the current cutoff\n",
    "  binary_predictions <- ifelse(final_predictions_vector > cutoff_values[i], 1, 0)\n",
    "  \n",
    "  # Compute confusion matrix\n",
    "  confusion <- table(binary_predictions, y_test_num)\n",
    "  \n",
    "  # Extract true positives, false positives, true negatives, false negatives\n",
    "  TP <- confusion[2, 2]\n",
    "  FP <- confusion[2, 1]\n",
    "  TN <- confusion[1, 1]\n",
    "  FN <- confusion[1, 2]\n",
    "  \n",
    "  # Calculate sensitivity, specificity, accuracy\n",
    "  sensitivity[i] <- TP / (TP + FN)\n",
    "  specificity[i] <- TN / (TN + FP)\n",
    "  accuracy[i] <- (TP + TN) / sum(confusion)\n",
    "}\n",
    "\n",
    "# Choose the cutoff with the maximum combined sensitivity and specificity\n",
    "combined_performance <- sensitivity + specificity\n",
    "best_cutoff_index <- which.max(combined_performance)\n",
    "best_cutoff <- cutoff_values[best_cutoff_index]\n",
    "\n",
    "# Use the best cutoff to compute the confusion matrix\n",
    "conf_matrix <- confusionMatrix(data = as.factor(ifelse(final_predictions_vector > best_cutoff, 1, 0)),\n",
    "                               reference = as.factor(ifelse(y_test_num == 1, 1, 0)))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
